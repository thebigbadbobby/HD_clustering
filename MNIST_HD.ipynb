{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from Module import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train=torch.from_numpy(x_train).reshape((-1,784)).float()\n",
    "x_test=torch.from_numpy(x_test).reshape((-1,784)).float()\n",
    "y_train=torch.from_numpy(y_train).long()\n",
    "y_test=torch.from_numpy(y_test).long()\n",
    "scaler = preprocessing.Normalizer().fit(x_train)\n",
    "x_train = torch.tensor(scaler.transform(x_train))\n",
    "x_test= torch.tensor(scaler.transform(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(size_thresh,entries,x_train,y_train,dim):\n",
    "    model1=HDCModel(1000,784,dim,classh=True)\n",
    "    classifier=FebHDVersion2(64,.0001)\n",
    "    classifier=TrainRepeater(classifier,5)\n",
    "    train_start(model1,classifier,x_train,y_train)\n",
    "    yhat1=model1(x_train)\n",
    "    print(\"done with initial training\")\n",
    "    accs=torch.zeros(len(yhat1.unique()))\n",
    "    sizes=torch.zeros(len(yhat1.unique()))\n",
    "    classification=torch.zeros(len(yhat1.unique()))\n",
    "    for i,ekans in enumerate(yhat1.unique()):\n",
    "        # arbok=yhat2[2]y_train==yhat\n",
    "        # print(ekans)\n",
    "        # print(arbok)\n",
    "        # print(y_train[yhat1==ekans].mode().values)\n",
    "        # print(y_train[yhat1==ekans][:10])\n",
    "        # print((y_train[yhat1==ekans]==y_train[yhat1==ekans].mode().values).float().mean())\n",
    "        classification[i]=y_train[yhat1==ekans].mode().values\n",
    "        istrue=(y_train[yhat1==ekans]==y_train[yhat1==ekans].mode().values).float()\n",
    "        accs[i]=istrue.mean()\n",
    "        sizes[i]=len(istrue)\n",
    "    print(\"done with computing metrics\")\n",
    "    hypervectors=torch.zeros(len(yhat1.unique()),model1.dimensionality)\n",
    "    for i,ekans in enumerate(yhat1.unique()):\n",
    "        hypervectors[i]=model1.encode(x_train[yhat1==ekans]).sum(0)\n",
    "    print(\"done with computing centroids\")\n",
    "    avgsims=torch.zeros(len(yhat1.unique()))\n",
    "    for j,i in enumerate(yhat1.unique()):\n",
    "        ekans=yhat1[i]\n",
    "        # arbok=yhat2[2]\n",
    "        # print(ekans)\n",
    "        # print(arbok)\n",
    "        avgsims[j]=cos_cdist(model1.encode(x_train[yhat1==ekans]),hypervectors[j].unsqueeze(0)).mean()\n",
    "    print(\"done with computing cosine deviation\")\n",
    "    is_optimized=sizes>size_thresh\n",
    "    entries=len(avgsims[is_optimized])\n",
    "    order=-avgsims[is_optimized].argsort()\n",
    "    print(sum(accs[is_optimized][order]*sizes[is_optimized][order])/sum(sizes[is_optimized][order]))\n",
    "    yhat1.unique()[is_optimized][order][:entries]\n",
    "    grouping=[]\n",
    "    for i in range(0,entries):\n",
    "        grouping.append((yhat1==yhat1.unique()[is_optimized][order][i]).nonzero().squeeze().tolist())\n",
    "    print(\"done with computing groupings\")\n",
    "    return grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniformity_report(index_list):\n",
    "    index_list=list(set(index_list))\n",
    "    realvals=torch.zeros(len(index_list))\n",
    "    for i, index in enumerate(index_list):\n",
    "        realvals[i]=y_train[index]\n",
    "    mode=realvals.mode()\n",
    "    return mode.values, len(y_train[index_list][y_train[index_list]==mode.values])/len(index_list),len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_groupings(comparison_grouping, category):\n",
    "    new_indices=[]\n",
    "    for i in range(0,len(list(category))):\n",
    "        new_indices+=comparison_grouping[list(category)[i]]\n",
    "    return new_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "def get_graph_from_adjacency_matrix(adjacency_matrix):\n",
    "    rows, cols = np.where(adjacency_matrix == 1)\n",
    "    edges = zip(rows.tolist(), cols.tolist())\n",
    "    gr = nx.Graph()\n",
    "    gr.add_edges_from(edges)\n",
    "    return gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Generate many homogenous clusters (febHD): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done with initial training\n",
      "done with computing metrics\n",
      "done with computing centroids\n",
      "done with computing cosine deviation\n",
      "tensor(0.9104)\n",
      "done with computing groupings\n",
      "done with initial training\n",
      "done with computing metrics\n",
      "done with computing centroids\n",
      "done with computing cosine deviation\n",
      "tensor(0.9136)\n",
      "done with computing groupings\n",
      "done with initial training\n",
      "done with computing metrics\n",
      "done with computing centroids\n",
      "done with computing cosine deviation\n",
      "tensor(0.9207)\n",
      "done with computing groupings\n"
     ]
    }
   ],
   "source": [
    "dim=2000\n",
    "\n",
    "size_thresh=25\n",
    "entries=10\n",
    "\n",
    "# sum(accs[is_optimized]*sizes[is_optimized])/sum(sizes[is_optimized])\n",
    "# original_grouping=get_classes(size_thresh,entries,x_train,y_train,dim)\n",
    "\n",
    "\n",
    "# generate overlapping groupings (may not even contain all of the points)\n",
    "\n",
    "comparison_grouping=[]\n",
    "for i in range(0,3):\n",
    "    comparison_grouping+=get_classes(size_thresh,entries,x_train,y_train,dim)\n",
    "\n",
    "#turn points into similarity matrix\n",
    "similarity_matrix=torch.zeros(len(comparison_grouping),len(comparison_grouping))\n",
    "for i,list_ in enumerate(comparison_grouping):\n",
    "    for j,comparison_list in enumerate(comparison_grouping):\n",
    "        similarity_matrix[i][j]=len(set(list_).intersection(comparison_list))\n",
    "\n",
    "#establish overlap threshold for generating adjacency matrix\n",
    "adjacency_matrix=similarity_matrix>=10\n",
    "#turn adjacency matrix into graph in preparation for community detection algorithm\n",
    "gr=get_graph_from_adjacency_matrix(adjacency_matrix)\n",
    "connected_components=nx.connected_components(gr)\n",
    "subgraphs=[gr.subgraph(c) for c in connected_components]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Detect more than 10 communities using community detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "(tensor(8.), 0.7786432516640702, 7061)\n",
      "16979\n",
      "(tensor(3.), 0.815024805102764, 7055)\n",
      "17216\n",
      "(tensor(0.), 0.9152037617554859, 6380)\n",
      "17900\n",
      "(tensor(4.), 0.832271396590322, 5807)\n",
      "13548\n",
      "(tensor(9.), 0.6951713969775156, 5426)\n",
      "12371\n",
      "(tensor(7.), 0.8996827315304426, 6619)\n",
      "17556\n",
      "(tensor(2.), 0.8070996147495872, 7268)\n",
      "18758\n",
      "(tensor(9.), 0.5836538461538462, 4160)\n",
      "9428\n",
      "(tensor(5.), 0.6837385756164857, 5799)\n",
      "12748\n",
      "(tensor(6.), 0.8969641214351426, 6522)\n",
      "17850\n",
      "(tensor(2.), 0.6491228070175439, 57)\n",
      "57\n",
      "(tensor(5.), 0.9003099173553719, 1936)\n",
      "4499\n",
      "(tensor(1.), 0.9617984131648546, 6806)\n",
      "19805\n",
      "(tensor(7.), 0.37142857142857144, 35)\n",
      "35\n",
      "0.8269812043263712\n"
     ]
    }
   ],
   "source": [
    "#Louvain community detection algorithm (Newman Eigenvector algorithm may also be appropriate)\n",
    "categories=nx.community.louvain_communities(gr, threshold=1e-10, seed=None)\n",
    "print(len(categories))\n",
    "sum_=0\n",
    "denom=0\n",
    "clusters=[]\n",
    "for i in range(0,len(categories)):\n",
    "    cluster=combine_groupings(comparison_grouping,categories[i])\n",
    "    denom+=len(cluster)*uniformity_report(cluster)[1]\n",
    "    sum_+=len(cluster)\n",
    "    print(uniformity_report(cluster))\n",
    "    print(len(cluster))\n",
    "    clusters.append(cluster)\n",
    "print(denom/sum_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just old stuff for reference\n",
    "targets=torch.zeros(len(y_train)) #new yhat for new classes to emulate umap\n",
    "i=0\n",
    "for indices in clusters:\n",
    "    for index in indices:\n",
    "        targets[index]==i\n",
    "    i+=1\n",
    "targets=targets.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-bbac9a6fc7b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcos_cdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "cos_cdist(model.encode(x), model.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3: resolve overlapping class assignments for each point\n",
    "for i in range(len(clusters)):\n",
    "    clusters[i]=torch.tensor(clusters[i])\n",
    "category_membership=torch.zeros(len(x_train))\n",
    "for index in range(len(x_train)):\n",
    "    assignment_vector=torch.zeros(len(clusters))\n",
    "    for i in range(len(clusters)):\n",
    "        assignment_vector[i]=len(clusters[i][clusters[i]==index])\n",
    "\n",
    "    category_membership[index]=assignment_vector.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: train an HDC model on the most common 10 classes\n",
    "model=HDCModel(classes=len(clusters),features=784,dim=2000,classh=True)\n",
    "classifier=ClassicVersion1(64,1)\n",
    "# classifier=ClassicVersion0(64,1)\n",
    "train_start(model,classifier,x_train,category_membership.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9344)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_acc(model,x_train,category_membership)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths=torch.zeros(len(model.classes))\n",
    "\n",
    "for i in range(0,len(model.classes)):\n",
    "    lengths[i]=len(yhat[yhat==i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classes=model.classes[torch.topk(lengths,10).indices] #only assign the top 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8725)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step 5: compute accuracy\n",
    "eval_inferred_acc(model,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extra stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 11., 12.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_membership.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6562"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(category_membership[category_membership==12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8192413342522029"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import fowlkes_mallows_score\n",
    "fowlkes_mallows_score(category_membership,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-85a4ae63086e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0myhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "labels=category_membership\n",
    "yhat=torch.zeros(y_train.shape)\n",
    "modes=[]\n",
    "for i in torch.unique(y_train):\n",
    "    n=torch.mode(y_train[labels==i]).values\n",
    "    modes.append(n)\n",
    "for i in range(y_train.shape[0]):\n",
    "    yhat[i]=modes[int(labels[i])]\n",
    "eval=[yhat[i]==y_train[i] for i in range(len(y_train))]\n",
    "print(sum(eval)/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6595\n",
      "5152\n",
      "5964\n",
      "5897\n",
      "6967\n",
      "5950\n",
      "5319\n",
      "5894\n",
      "6207\n",
      "6055\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(clusters)):\n",
    "    print(len(labels[labels==i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_membership.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities=cos_cdist(model.encode(x_train), model.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 14])\n"
     ]
    }
   ],
   "source": [
    "print(similarities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities=similarities.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dim_vec = similarities\n",
    "vectors_list = np.array_split(reduced_dim_vec, len(reduced_dim_vec))\n",
    "category_assignments=pd.Series(vectors_list).apply(lambda x: x.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [0.57468, 0.6285479, 0.5455284, 0.5325451, 0.5...\n",
       "1        [0.5372889, 0.5457319, 0.650884, 0.539474, 0.5...\n",
       "2        [0.5048593, 0.5196212, 0.4901391, 0.5671302, 0...\n",
       "3        [0.5663998, 0.54452395, 0.51290345, 0.5775483,...\n",
       "4        [0.58430296, 0.5444071, 0.5390455, 0.61799, 0....\n",
       "                               ...                        \n",
       "59995    [0.6090697, 0.56485844, 0.52651197, 0.5605037,...\n",
       "59996    [0.6055812, 0.6474652, 0.53547484, 0.5355785, ...\n",
       "59997    [0.55851996, 0.57203615, 0.54585, 0.54019326, ...\n",
       "59998    [0.5564495, 0.5572184, 0.56590635, 0.5607771, ...\n",
       "59999    [0.58963406, 0.5420234, 0.55819845, 0.57017237...\n",
       "Length: 60000, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_membership.long().dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
